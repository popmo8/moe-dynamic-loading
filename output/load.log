[After initialize model skeleton] GPU memory allocated: 0.000 GB, reserved: 0.000 GB
Model Initial Structure:
GptOssForCausalLM(
  (model): GptOssModel(
    (embed_tokens): Embedding(201088, 2880, padding_idx=199999)
    (layers): ModuleList(
      (0-23): 24 x GptOssDecoderLayer(
        (self_attn): GptOssAttention(
          (q_proj): Linear(in_features=2880, out_features=4096, bias=True)
          (k_proj): Linear(in_features=2880, out_features=512, bias=True)
          (v_proj): Linear(in_features=2880, out_features=512, bias=True)
          (o_proj): Linear(in_features=4096, out_features=2880, bias=True)
        )
        (mlp): GptOssMLP(
          (router): GptOssTopKRouter()
          (experts): GptOssExperts()
        )
        (input_layernorm): GptOssRMSNorm((2880,), eps=1e-05)
        (post_attention_layernorm): GptOssRMSNorm((2880,), eps=1e-05)
      )
    )
    (norm): GptOssRMSNorm((2880,), eps=1e-05)
    (rotary_emb): GptOssRotaryEmbedding()
  )
  (lm_head): Linear(in_features=2880, out_features=201088, bias=False)
)
Loaded model.embed_tokens into the model.
Loaded model.layers.0.self_attn.q_proj into the model.
Loaded model.layers.0.self_attn.k_proj into the model.
Loaded model.layers.0.self_attn.v_proj into the model.
Loaded model.layers.0.self_attn.o_proj into the model.
Loaded model.layers.0.mlp.router into the model.
Loaded model.layers.0.input_layernorm into the model.
Loaded model.layers.0.post_attention_layernorm into the model.
Loaded model.layers.1.self_attn.q_proj into the model.
Loaded model.layers.1.self_attn.k_proj into the model.
Loaded model.layers.1.self_attn.v_proj into the model.
Loaded model.layers.1.self_attn.o_proj into the model.
Loaded model.layers.1.mlp.router into the model.
Loaded model.layers.1.input_layernorm into the model.
Loaded model.layers.1.post_attention_layernorm into the model.
Loaded model.layers.2.self_attn.q_proj into the model.
Loaded model.layers.2.self_attn.k_proj into the model.
Loaded model.layers.2.self_attn.v_proj into the model.
Loaded model.layers.2.self_attn.o_proj into the model.
Loaded model.layers.2.mlp.router into the model.
Loaded model.layers.2.input_layernorm into the model.
Loaded model.layers.2.post_attention_layernorm into the model.
Loaded model.layers.3.self_attn.q_proj into the model.
Loaded model.layers.3.self_attn.k_proj into the model.
Loaded model.layers.3.self_attn.v_proj into the model.
Loaded model.layers.3.self_attn.o_proj into the model.
Loaded model.layers.3.mlp.router into the model.
Loaded model.layers.3.input_layernorm into the model.
Loaded model.layers.3.post_attention_layernorm into the model.
Loaded model.layers.4.self_attn.q_proj into the model.
Loaded model.layers.4.self_attn.k_proj into the model.
Loaded model.layers.4.self_attn.v_proj into the model.
Loaded model.layers.4.self_attn.o_proj into the model.
Loaded model.layers.4.mlp.router into the model.
Loaded model.layers.4.input_layernorm into the model.
Loaded model.layers.4.post_attention_layernorm into the model.
Loaded model.layers.5.self_attn.q_proj into the model.
Loaded model.layers.5.self_attn.k_proj into the model.
Loaded model.layers.5.self_attn.v_proj into the model.
Loaded model.layers.5.self_attn.o_proj into the model.
Loaded model.layers.5.mlp.router into the model.
Loaded model.layers.5.input_layernorm into the model.
Loaded model.layers.5.post_attention_layernorm into the model.
Loaded model.layers.6.self_attn.q_proj into the model.
Loaded model.layers.6.self_attn.k_proj into the model.
Loaded model.layers.6.self_attn.v_proj into the model.
Loaded model.layers.6.self_attn.o_proj into the model.
Loaded model.layers.6.mlp.router into the model.
Loaded model.layers.6.input_layernorm into the model.
Loaded model.layers.6.post_attention_layernorm into the model.
Loaded model.layers.7.self_attn.q_proj into the model.
Loaded model.layers.7.self_attn.k_proj into the model.
Loaded model.layers.7.self_attn.v_proj into the model.
Loaded model.layers.7.self_attn.o_proj into the model.
Loaded model.layers.7.mlp.router into the model.
Loaded model.layers.7.input_layernorm into the model.
Loaded model.layers.7.post_attention_layernorm into the model.
Loaded model.layers.8.self_attn.q_proj into the model.
Loaded model.layers.8.self_attn.k_proj into the model.
Loaded model.layers.8.self_attn.v_proj into the model.
Loaded model.layers.8.self_attn.o_proj into the model.
Loaded model.layers.8.mlp.router into the model.
Loaded model.layers.8.input_layernorm into the model.
Loaded model.layers.8.post_attention_layernorm into the model.
Loaded model.layers.9.self_attn.q_proj into the model.
Loaded model.layers.9.self_attn.k_proj into the model.
Loaded model.layers.9.self_attn.v_proj into the model.
Loaded model.layers.9.self_attn.o_proj into the model.
Loaded model.layers.9.mlp.router into the model.
Loaded model.layers.9.input_layernorm into the model.
Loaded model.layers.9.post_attention_layernorm into the model.
Loaded model.layers.10.self_attn.q_proj into the model.
Loaded model.layers.10.self_attn.k_proj into the model.
Loaded model.layers.10.self_attn.v_proj into the model.
Loaded model.layers.10.self_attn.o_proj into the model.
Loaded model.layers.10.mlp.router into the model.
Loaded model.layers.10.input_layernorm into the model.
Loaded model.layers.10.post_attention_layernorm into the model.
Loaded model.layers.11.self_attn.q_proj into the model.
Loaded model.layers.11.self_attn.k_proj into the model.
Loaded model.layers.11.self_attn.v_proj into the model.
Loaded model.layers.11.self_attn.o_proj into the model.
Loaded model.layers.11.mlp.router into the model.
Loaded model.layers.11.input_layernorm into the model.
Loaded model.layers.11.post_attention_layernorm into the model.
Loaded model.layers.12.self_attn.q_proj into the model.
Loaded model.layers.12.self_attn.k_proj into the model.
Loaded model.layers.12.self_attn.v_proj into the model.
Loaded model.layers.12.self_attn.o_proj into the model.
Loaded model.layers.12.mlp.router into the model.
Loaded model.layers.12.input_layernorm into the model.
Loaded model.layers.12.post_attention_layernorm into the model.
Loaded model.layers.13.self_attn.q_proj into the model.
Loaded model.layers.13.self_attn.k_proj into the model.
Loaded model.layers.13.self_attn.v_proj into the model.
Loaded model.layers.13.self_attn.o_proj into the model.
Loaded model.layers.13.mlp.router into the model.
Loaded model.layers.13.input_layernorm into the model.
Loaded model.layers.13.post_attention_layernorm into the model.
Loaded model.layers.14.self_attn.q_proj into the model.
Loaded model.layers.14.self_attn.k_proj into the model.
Loaded model.layers.14.self_attn.v_proj into the model.
Loaded model.layers.14.self_attn.o_proj into the model.
Loaded model.layers.14.mlp.router into the model.
Loaded model.layers.14.input_layernorm into the model.
Loaded model.layers.14.post_attention_layernorm into the model.
Loaded model.layers.15.self_attn.q_proj into the model.
Loaded model.layers.15.self_attn.k_proj into the model.
Loaded model.layers.15.self_attn.v_proj into the model.
Loaded model.layers.15.self_attn.o_proj into the model.
Loaded model.layers.15.mlp.router into the model.
Loaded model.layers.15.input_layernorm into the model.
Loaded model.layers.15.post_attention_layernorm into the model.
Loaded model.layers.16.self_attn.q_proj into the model.
Loaded model.layers.16.self_attn.k_proj into the model.
Loaded model.layers.16.self_attn.v_proj into the model.
Loaded model.layers.16.self_attn.o_proj into the model.
Loaded model.layers.16.mlp.router into the model.
Loaded model.layers.16.input_layernorm into the model.
Loaded model.layers.16.post_attention_layernorm into the model.
Loaded model.layers.17.self_attn.q_proj into the model.
Loaded model.layers.17.self_attn.k_proj into the model.
Loaded model.layers.17.self_attn.v_proj into the model.
Loaded model.layers.17.self_attn.o_proj into the model.
Loaded model.layers.17.mlp.router into the model.
Loaded model.layers.17.input_layernorm into the model.
Loaded model.layers.17.post_attention_layernorm into the model.
Loaded model.layers.18.self_attn.q_proj into the model.
Loaded model.layers.18.self_attn.k_proj into the model.
Loaded model.layers.18.self_attn.v_proj into the model.
Loaded model.layers.18.self_attn.o_proj into the model.
Loaded model.layers.18.mlp.router into the model.
Loaded model.layers.18.input_layernorm into the model.
Loaded model.layers.18.post_attention_layernorm into the model.
Loaded model.layers.19.self_attn.q_proj into the model.
Loaded model.layers.19.self_attn.k_proj into the model.
Loaded model.layers.19.self_attn.v_proj into the model.
Loaded model.layers.19.self_attn.o_proj into the model.
Loaded model.layers.19.mlp.router into the model.
Loaded model.layers.19.input_layernorm into the model.
Loaded model.layers.19.post_attention_layernorm into the model.
Loaded model.layers.20.self_attn.q_proj into the model.
Loaded model.layers.20.self_attn.k_proj into the model.
Loaded model.layers.20.self_attn.v_proj into the model.
Loaded model.layers.20.self_attn.o_proj into the model.
Loaded model.layers.20.mlp.router into the model.
Loaded model.layers.20.input_layernorm into the model.
Loaded model.layers.20.post_attention_layernorm into the model.
Loaded model.layers.21.self_attn.q_proj into the model.
Loaded model.layers.21.self_attn.k_proj into the model.
Loaded model.layers.21.self_attn.v_proj into the model.
Loaded model.layers.21.self_attn.o_proj into the model.
Loaded model.layers.21.mlp.router into the model.
Loaded model.layers.21.input_layernorm into the model.
Loaded model.layers.21.post_attention_layernorm into the model.
Loaded model.layers.22.self_attn.q_proj into the model.
Loaded model.layers.22.self_attn.k_proj into the model.
Loaded model.layers.22.self_attn.v_proj into the model.
Loaded model.layers.22.self_attn.o_proj into the model.
Loaded model.layers.22.mlp.router into the model.
Loaded model.layers.22.input_layernorm into the model.
Loaded model.layers.22.post_attention_layernorm into the model.
Loaded model.layers.23.self_attn.q_proj into the model.
Loaded model.layers.23.self_attn.k_proj into the model.
Loaded model.layers.23.self_attn.v_proj into the model.
Loaded model.layers.23.self_attn.o_proj into the model.
Loaded model.layers.23.mlp.router into the model.
Loaded model.layers.23.input_layernorm into the model.
Loaded model.layers.23.post_attention_layernorm into the model.
Loaded model.norm into the model.
Loaded model.rotary_emb into the model.
Loaded lm_head into the model.
[After loading non-expert layers] GPU memory allocated: 1.079 GB, reserved: 1.105 GB
[After replacing experts layers and moving model to GPU] GPU memory allocated: 7.825 GB, reserved: 7.879 GB
Model Structure After Replacement:
GptOssForCausalLM(
  (model): GptOssModel(
    (embed_tokens): Embedding(201088, 2880, padding_idx=199999)
    (layers): ModuleList(
      (0-23): 24 x GptOssDecoderLayer(
        (self_attn): GptOssAttention(
          (q_proj): Linear(in_features=2880, out_features=4096, bias=True)
          (k_proj): Linear(in_features=2880, out_features=512, bias=True)
          (v_proj): Linear(in_features=2880, out_features=512, bias=True)
          (o_proj): Linear(in_features=4096, out_features=2880, bias=True)
        )
        (mlp): GptOssMLP(
          (router): GptOssTopKRouter()
          (experts): LoadExperts()
        )
        (input_layernorm): GptOssRMSNorm((2880,), eps=1e-05)
        (post_attention_layernorm): GptOssRMSNorm((2880,), eps=1e-05)
      )
    )
    (norm): GptOssRMSNorm((2880,), eps=1e-05)
    (rotary_emb): GptOssRotaryEmbedding()
  )
  (lm_head): Linear(in_features=2880, out_features=201088, bias=False)
)
[After loading all expert weights] GPU memory allocated: 9.344 GB, reserved: 9.402 GB
================ Layer 0 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.345 GB, reserved: 9.539 GB
================ Layer 1 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.345 GB, reserved: 9.541 GB
================ Layer 2 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.346 GB, reserved: 9.541 GB
================ Layer 3 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.346 GB, reserved: 9.541 GB
================ Layer 4 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.346 GB, reserved: 9.541 GB
================ Layer 5 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.347 GB, reserved: 9.543 GB
================ Layer 6 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.347 GB, reserved: 9.543 GB
================ Layer 7 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.347 GB, reserved: 9.543 GB
================ Layer 8 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.347 GB, reserved: 9.543 GB
================ Layer 9 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.348 GB, reserved: 9.543 GB
================ Layer 10 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.348 GB, reserved: 9.543 GB
================ Layer 11 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.348 GB, reserved: 9.545 GB
================ Layer 12 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.349 GB, reserved: 9.545 GB
================ Layer 13 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.349 GB, reserved: 9.545 GB
================ Layer 14 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.349 GB, reserved: 9.545 GB
================ Layer 15 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.349 GB, reserved: 9.545 GB
================ Layer 16 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.350 GB, reserved: 9.545 GB
================ Layer 17 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.350 GB, reserved: 9.547 GB
================ Layer 18 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.350 GB, reserved: 9.547 GB
================ Layer 19 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.351 GB, reserved: 9.547 GB
================ Layer 20 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.351 GB, reserved: 9.547 GB
================ Layer 21 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.351 GB, reserved: 9.547 GB
================ Layer 22 1-th token inference finished ===================
[After loading all expert weights] GPU memory allocated: 9.352 GB, reserved: 9.547 GB
================ Layer 23 1-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 0 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 1 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 2 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 3 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 4 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 5 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 6 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 7 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 8 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 9 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 10 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 11 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 12 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 13 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 14 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 15 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 16 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 17 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 18 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 19 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 20 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 21 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 22 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 23 2-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 0 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 1 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 2 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 3 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 4 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 5 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 6 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 7 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 8 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 9 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 10 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 11 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 12 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 13 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 14 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 15 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 16 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 17 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.617 GB
================ Layer 18 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 19 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 20 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 21 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 22 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 23 3-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 0 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 1 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 2 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 3 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 4 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 5 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 6 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 7 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 8 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 9 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 10 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 11 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 12 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 13 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 14 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 15 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 16 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 17 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 18 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 19 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 20 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 21 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 22 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 23 4-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 0 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 1 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 2 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 3 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 4 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 5 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 6 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 7 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 8 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 9 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 10 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 11 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 12 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 13 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 14 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 15 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 16 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 17 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 18 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 19 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 20 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 21 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 22 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 23 5-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 0 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 1 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 2 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 3 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 4 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 5 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 6 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 7 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 8 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 9 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 10 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 11 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 12 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 13 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 14 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 15 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 16 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 17 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 18 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 19 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 20 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 21 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 22 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 23 6-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.282 GB, reserved: 15.619 GB
================ Layer 0 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 1 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 2 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 3 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 4 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 5 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 6 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 7 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 8 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 9 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 10 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 11 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 12 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 13 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 14 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 15 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 16 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 17 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 18 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 19 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 20 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 21 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 22 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 23 7-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 0 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 1 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 2 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 3 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 4 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 5 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 6 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 7 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 8 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 9 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 10 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 11 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 12 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 13 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 14 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 15 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 16 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 17 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 18 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 19 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 20 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 21 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 22 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 23 8-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 0 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 1 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 2 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 3 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 4 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 5 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 6 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 7 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 8 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 9 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 10 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 11 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 12 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 13 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 14 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 15 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 16 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 17 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 18 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 19 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 20 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 21 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 22 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 23 9-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 0 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 1 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 2 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 3 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 4 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 5 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 6 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 7 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 8 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 9 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 10 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 11 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 12 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 13 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 14 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 15 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 16 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 17 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 18 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 19 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 20 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 21 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 22 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 23 10-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 0 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 1 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 2 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 3 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 4 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 5 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 6 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 7 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 8 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 9 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 10 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 11 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 12 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 13 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 14 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 15 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 16 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 17 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 18 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 19 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 20 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 21 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 22 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 23 11-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 0 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 1 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 2 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 3 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 4 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 5 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 6 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 7 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 8 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 9 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 10 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 11 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 12 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 13 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 14 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 15 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 16 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 17 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 18 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 19 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 20 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 21 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 22 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 23 12-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 0 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 1 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 2 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 3 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 4 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 5 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 6 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 7 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 8 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 9 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 10 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 11 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 12 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 13 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 14 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 15 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 16 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 17 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 18 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 19 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 20 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 21 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 22 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 23 13-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 0 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 1 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 2 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 3 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 4 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 5 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 6 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 7 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 8 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 9 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 10 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 11 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 12 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 13 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 14 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 15 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 16 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 17 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 18 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 19 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 20 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 21 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 22 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 23 14-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 0 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 1 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 2 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 3 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 4 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 5 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 6 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 7 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 8 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 9 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 10 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 11 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 12 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 13 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 14 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 15 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 16 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 17 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 18 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 19 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 20 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 21 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 22 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 23 15-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 0 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 1 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 2 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 3 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 4 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 5 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 6 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 7 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 8 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 9 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 10 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 11 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 12 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 13 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 14 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 15 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 16 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 17 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 18 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 19 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 20 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 21 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 22 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 23 16-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 0 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 1 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 2 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 3 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 4 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 5 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 6 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 7 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 8 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 9 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 10 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 11 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 12 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 13 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 14 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 15 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 16 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 17 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 18 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 19 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 20 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 21 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 22 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 23 17-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.283 GB, reserved: 15.619 GB
================ Layer 0 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 1 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 2 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 3 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 4 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 5 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 6 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 7 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 8 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 9 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 10 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 11 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 12 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 13 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 14 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 15 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 16 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 17 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 18 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 19 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 20 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 21 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 22 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 23 18-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 0 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 1 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 2 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 3 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 4 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 5 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 6 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 7 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 8 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 9 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 10 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 11 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 12 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 13 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 14 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 15 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 16 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 17 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 18 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 19 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 20 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 21 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 22 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 23 19-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 0 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 1 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 2 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 3 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 4 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 5 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 6 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 7 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 8 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 9 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 10 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 11 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 12 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 13 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 14 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 15 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 16 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 17 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 18 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 19 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 20 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 21 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 22 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 23 20-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 0 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 1 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 2 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 3 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 4 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 5 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 6 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 7 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 8 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 9 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 10 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 11 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 12 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 13 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 14 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 15 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 16 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 17 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 18 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 19 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 20 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 21 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 22 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 23 21-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 0 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 1 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 2 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 3 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 4 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 5 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 6 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 7 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 8 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 9 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 10 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 11 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 12 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 13 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 14 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 15 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 16 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 17 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 18 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 19 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 20 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 21 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 22 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 23 22-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 0 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 1 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 2 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 3 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 4 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 5 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 6 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 7 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 8 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 9 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 10 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 11 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 12 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 13 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 14 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 15 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 16 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 17 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 18 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 19 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 20 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 21 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 22 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 23 23-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 0 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 1 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 2 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 3 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 4 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 5 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 6 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 7 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 8 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 9 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 10 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 11 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 12 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 13 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 14 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 15 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 16 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 17 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 18 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 19 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 20 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 21 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 22 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 23 24-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 0 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 1 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 2 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 3 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 4 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 5 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 6 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 7 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 8 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 9 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 10 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 11 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 12 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 13 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 14 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 15 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 16 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 17 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 18 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 19 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 20 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 21 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 22 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 23 25-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 0 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 1 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 2 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 3 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 4 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 5 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 6 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 7 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 8 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 9 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 10 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 11 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 12 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 13 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 14 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 15 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 16 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 17 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 18 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 19 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 20 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 21 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 22 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 23 26-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 0 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 1 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 2 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 3 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 4 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 5 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 6 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 7 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 8 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 9 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 10 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 11 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 12 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 13 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 14 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 15 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 16 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 17 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 18 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 19 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 20 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 21 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 22 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 23 27-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 0 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 1 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 2 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 3 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 4 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 5 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 6 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 7 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 8 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 9 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 10 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 11 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 12 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 13 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 14 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 15 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 16 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 17 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.284 GB, reserved: 15.619 GB
================ Layer 18 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 19 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 20 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 21 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 22 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 23 28-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 0 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 1 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 2 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 3 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 4 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 5 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 6 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 7 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 8 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 9 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 10 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 11 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 12 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 13 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 14 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 15 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 16 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 17 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 18 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 19 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 20 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 21 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 22 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 23 29-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 0 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 1 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 2 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 3 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.619 GB
================ Layer 4 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 5 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 6 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 7 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 8 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 9 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 10 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 11 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 12 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 13 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 14 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 15 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 16 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 17 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 18 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 19 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 20 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 21 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 22 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 23 30-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 0 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 1 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 2 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 3 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 4 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 5 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 6 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 7 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 8 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 9 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 10 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 11 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 12 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 13 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 14 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 15 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 16 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 17 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 18 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 19 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 20 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 21 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 22 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 23 31-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 0 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 1 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 2 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 3 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 4 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 5 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 6 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 7 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 8 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 9 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 10 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 11 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 12 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 13 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 14 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 15 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 16 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 17 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 18 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 19 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 20 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 21 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 22 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 23 32-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 0 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 1 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 2 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 3 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 4 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 5 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 6 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 7 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 8 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 9 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 10 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 11 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 12 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 13 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 14 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 15 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 16 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 17 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 18 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 19 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 20 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 21 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 22 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 23 33-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 0 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 1 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 2 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 3 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 4 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 5 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 6 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 7 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 8 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 9 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 10 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 11 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 12 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 13 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 14 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 15 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 16 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 17 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 18 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 19 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 20 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 21 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 22 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 23 34-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 0 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 1 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 2 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 3 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 4 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 5 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 6 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 7 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 8 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 9 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 10 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 11 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 12 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 13 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 14 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 15 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 16 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 17 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 18 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 19 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 20 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 21 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 22 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 23 35-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 0 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 1 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 2 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 3 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 4 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 5 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 6 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 7 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 8 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 9 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 10 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 11 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 12 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 13 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 14 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 15 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 16 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 17 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 18 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 19 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 20 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 21 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 22 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 23 36-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 0 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 1 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 2 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 3 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 4 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 5 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 6 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 7 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 8 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 9 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 10 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 11 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 12 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 13 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 14 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 15 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 16 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 17 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 18 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 19 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 20 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 21 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 22 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 23 37-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 0 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 1 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 2 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 3 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 4 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 5 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 6 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 7 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 8 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 9 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 10 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 11 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 12 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 13 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 14 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 15 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 16 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 17 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 18 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 19 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 20 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 21 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 22 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 23 38-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 0 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 1 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 2 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 3 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 4 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 5 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 6 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 7 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 8 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 9 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 10 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 11 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 12 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 13 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 14 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 15 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.285 GB, reserved: 15.621 GB
================ Layer 16 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 17 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 18 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 19 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 20 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 21 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 22 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 23 39-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 0 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 1 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 2 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 3 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 4 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 5 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 6 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 7 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 8 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 9 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 10 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 11 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 12 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 13 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 14 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 15 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 16 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 17 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 18 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 19 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 20 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 21 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 22 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 23 40-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 0 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 1 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 2 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 3 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 4 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 5 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 6 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 7 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 8 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 9 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 10 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 11 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 12 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 13 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 14 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 15 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 16 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 17 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 18 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 19 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 20 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 21 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 22 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 23 41-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 0 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 1 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 2 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 3 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 4 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 5 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 6 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 7 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 8 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 9 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 10 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 11 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 12 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 13 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 14 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 15 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 16 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 17 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 18 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 19 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 20 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 21 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 22 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 23 42-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 0 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 1 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 2 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 3 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 4 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 5 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 6 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 7 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 8 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 9 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 10 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 11 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 12 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 13 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 14 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 15 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 16 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 17 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 18 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 19 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 20 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 21 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 22 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 23 43-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 0 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 1 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 2 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 3 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 4 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 5 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 6 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 7 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 8 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 9 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 10 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 11 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 12 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 13 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 14 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 15 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 16 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 17 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 18 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 19 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 20 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 21 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 22 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 23 44-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 0 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 1 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 2 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 3 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 4 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 5 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 6 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 7 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 8 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 9 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 10 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 11 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 12 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 13 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 14 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 15 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 16 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 17 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 18 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 19 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 20 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 21 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 22 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 23 45-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 0 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 1 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 2 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 3 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 4 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 5 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 6 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 7 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 8 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 9 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 10 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 11 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 12 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 13 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 14 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 15 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 16 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 17 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 18 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 19 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 20 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 21 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 22 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 23 46-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 0 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 1 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 2 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 3 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 4 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 5 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 6 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 7 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 8 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 9 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 10 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 11 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 12 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 13 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 14 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 15 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 16 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 17 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 18 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 19 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 20 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 21 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 22 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 23 47-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 0 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 1 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 2 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 3 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 4 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 5 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 6 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 7 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 8 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 9 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 10 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 11 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 12 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 13 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 14 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 15 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 16 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 17 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 18 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 19 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 20 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 21 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 22 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 23 48-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 0 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 1 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 2 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 3 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 4 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 5 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 6 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 7 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 8 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 9 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 10 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 11 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 12 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 13 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 14 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 15 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 16 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 17 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 18 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 19 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 20 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 21 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 22 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 23 49-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 0 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 1 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 2 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 3 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 4 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 5 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 6 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 7 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 8 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 9 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 10 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 11 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 12 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.286 GB, reserved: 15.621 GB
================ Layer 13 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 14 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 15 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 16 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 17 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 18 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 19 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 20 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 21 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 22 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 23 50-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 0 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 1 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 2 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 3 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 4 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 5 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 6 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 7 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 8 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 9 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 10 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 11 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 12 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 13 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 14 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 15 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 16 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 17 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 18 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 19 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 20 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 21 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 22 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 23 51-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 0 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 1 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 2 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 3 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 4 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 5 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 6 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 7 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 8 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 9 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 10 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 11 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 12 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 13 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 14 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 15 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 16 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 17 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 18 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 19 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 20 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 21 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 22 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.621 GB
================ Layer 23 52-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 0 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 1 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 2 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 3 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 4 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 5 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 6 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 7 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 8 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 9 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 10 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 11 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 12 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 13 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 14 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 15 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 16 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 17 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 18 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 19 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 20 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 21 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 22 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 23 53-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 0 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 1 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 2 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 3 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 4 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 5 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 6 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 7 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 8 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 9 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 10 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 11 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 12 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 13 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 14 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 15 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 16 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 17 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 18 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 19 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 20 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 21 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 22 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 23 54-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 0 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 1 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 2 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 3 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 4 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 5 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 6 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 7 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 8 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 9 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 10 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 11 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 12 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 13 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 14 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 15 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 16 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 17 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 18 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 19 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 20 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 21 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 22 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 23 55-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 0 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 1 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 2 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 3 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 4 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 5 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 6 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 7 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 8 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 9 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 10 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 11 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 12 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 13 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 14 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 15 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 16 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 17 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 18 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 19 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 20 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 21 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 22 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 23 56-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 0 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 1 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 2 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 3 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 4 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 5 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 6 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 7 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 8 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 9 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 10 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 11 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 12 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 13 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 14 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 15 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 16 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 17 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 18 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 19 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 20 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 21 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 22 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 23 57-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 0 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 1 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 2 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 3 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 4 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 5 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 6 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 7 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 8 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 9 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 10 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 11 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 12 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 13 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 14 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 15 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 16 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 17 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 18 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 19 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 20 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 21 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 22 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 23 58-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 0 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 1 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 2 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 3 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 4 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 5 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 6 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 7 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 8 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 9 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 10 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 11 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 12 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 13 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 14 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 15 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 16 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 17 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 18 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 19 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 20 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 21 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 22 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 23 59-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 0 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 1 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 2 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 3 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 4 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 5 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 6 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 7 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 8 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 9 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 10 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 11 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 12 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 13 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 14 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 15 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 16 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 17 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 18 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 19 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 20 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 21 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 22 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 23 60-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 0 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 1 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 2 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 3 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 4 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 5 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 6 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 7 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 8 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 9 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.287 GB, reserved: 15.623 GB
================ Layer 10 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 11 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 12 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 13 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 14 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 15 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 16 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 17 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 18 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 19 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 20 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 21 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 22 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.623 GB
================ Layer 23 61-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 0 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 1 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 2 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 3 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 4 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 5 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 6 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 7 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 8 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 9 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 10 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 11 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 12 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 13 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 14 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 15 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 16 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 17 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 18 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 19 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 20 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 21 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 22 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 23 62-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 0 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 1 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 2 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 3 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 4 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 5 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 6 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 7 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 8 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 9 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 10 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 11 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 12 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 13 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 14 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 15 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 16 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 17 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 18 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 19 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 20 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 21 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 22 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 23 63-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 0 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 1 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 2 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 3 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 4 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 5 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 6 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 7 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 8 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 9 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 10 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 11 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 12 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 13 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 14 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 15 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 16 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 17 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 18 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 19 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 20 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 21 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 22 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 23 64-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 0 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 1 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 2 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 3 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 4 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 5 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 6 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 7 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 8 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 9 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 10 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 11 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 12 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 13 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 14 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 15 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 16 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 17 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 18 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 19 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 20 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 21 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 22 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 23 65-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 0 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 1 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 2 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 3 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 4 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 5 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 6 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 7 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 8 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 9 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 10 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 11 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 12 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 13 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 14 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 15 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 16 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 17 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 18 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 19 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 20 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 21 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 22 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 23 66-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 0 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 1 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 2 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 3 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 4 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 5 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 6 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 7 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 8 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 9 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 10 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 11 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 12 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 13 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 14 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 15 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 16 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 17 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 18 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 19 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 20 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 21 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 22 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 23 67-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 0 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 1 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 2 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 3 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 4 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 5 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 6 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 7 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 8 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 9 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 10 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 11 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 12 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 13 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 14 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 15 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 16 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 17 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 18 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 19 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 20 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 21 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 22 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 23 68-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 0 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 1 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 2 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 3 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 4 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 5 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 6 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 7 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 8 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 9 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 10 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 11 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 12 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 13 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 14 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 15 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 16 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 17 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 18 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 19 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 20 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 21 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 22 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 23 69-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 0 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 1 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 2 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 3 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 4 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 5 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 6 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 7 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 8 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 9 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 10 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 11 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 12 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 13 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 14 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 15 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 16 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 17 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 18 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 19 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 20 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 21 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 22 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 23 70-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 0 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 1 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 2 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 3 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 4 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 5 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 6 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 7 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 8 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 9 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 10 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 11 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 12 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 13 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 14 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 15 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 16 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 17 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 18 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 19 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 20 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 21 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 22 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 23 71-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 0 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 1 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 2 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 3 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 4 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 5 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 6 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 7 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.288 GB, reserved: 15.625 GB
================ Layer 8 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 9 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 10 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 11 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 12 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 13 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 14 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 15 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 16 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 17 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 18 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 19 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 20 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 21 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 22 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 23 72-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 0 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 1 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 2 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 3 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 4 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 5 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 6 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 7 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 8 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 9 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 10 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 11 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 12 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 13 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 14 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 15 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 16 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 17 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 18 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 19 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 20 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 21 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 22 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 23 73-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 0 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 1 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 2 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 3 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 4 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 5 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 6 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 7 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 8 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 9 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 10 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 11 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 12 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 13 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 14 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 15 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 16 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 17 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 18 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 19 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 20 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 21 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 22 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 23 74-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 0 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 1 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 2 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 3 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 4 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 5 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 6 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 7 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 8 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 9 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 10 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 11 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 12 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 13 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 14 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 15 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 16 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 17 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 18 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 19 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 20 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 21 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 22 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 23 75-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 0 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 1 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 2 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 3 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 4 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 5 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 6 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 7 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 8 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 9 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 10 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 11 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 12 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 13 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 14 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 15 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 16 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 17 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 18 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 19 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 20 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 21 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 22 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 23 76-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 0 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 1 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 2 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 3 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 4 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 5 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 6 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 7 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 8 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 9 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 10 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 11 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 12 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 13 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 14 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 15 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 16 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 17 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 18 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 19 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 20 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 21 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 22 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 23 77-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 0 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 1 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 2 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 3 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 4 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 5 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 6 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 7 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 8 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 9 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 10 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 11 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 12 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 13 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 14 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 15 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 16 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 17 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 18 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 19 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 20 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 21 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 22 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 23 78-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 0 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 1 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 2 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 3 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 4 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 5 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 6 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 7 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 8 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 9 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 10 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 11 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 12 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 13 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 14 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 15 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 16 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 17 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 18 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 19 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 20 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 21 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 22 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 23 79-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 0 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 1 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 2 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 3 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 4 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 5 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 6 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 7 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 8 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 9 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 10 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 11 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 12 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 13 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 14 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 15 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 16 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 17 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 18 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 19 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 20 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 21 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 22 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 23 80-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 0 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 1 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 2 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 3 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 4 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 5 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 6 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 7 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 8 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 9 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 10 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 11 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 12 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 13 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 14 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 15 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 16 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 17 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 18 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 19 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 20 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 21 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 22 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 23 81-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 0 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 1 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 2 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 3 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 4 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 5 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 6 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 7 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 8 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 9 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 10 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 11 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 12 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 13 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 14 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 15 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 16 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 17 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 18 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 19 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 20 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 21 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 22 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 23 82-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 0 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 1 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 2 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 3 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 4 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.289 GB, reserved: 15.625 GB
================ Layer 5 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 6 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 7 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 8 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 9 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 10 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 11 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 12 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 13 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 14 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 15 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 16 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 17 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 18 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 19 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 20 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 21 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 22 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 23 83-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 0 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 1 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 2 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 3 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 4 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 5 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 6 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 7 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 8 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 9 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 10 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 11 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 12 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 13 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 14 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 15 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 16 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 17 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 18 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 19 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 20 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 21 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 22 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 23 84-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 0 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 1 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 2 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 3 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 4 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 5 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 6 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 7 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 8 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 9 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 10 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 11 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 12 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 13 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 14 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 15 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 16 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 17 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 18 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 19 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 20 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 21 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 22 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.625 GB
================ Layer 23 85-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 0 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 1 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 2 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 3 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 4 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 5 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 6 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 7 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 8 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 9 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 10 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 11 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 12 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 13 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 14 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 15 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 16 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 17 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 18 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 19 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 20 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 21 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 22 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 23 86-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 0 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 1 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 2 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 3 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 4 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 5 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 6 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 7 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 8 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 9 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 10 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 11 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 12 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 13 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 14 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 15 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 16 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 17 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 18 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 19 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 20 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 21 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 22 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 23 87-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 0 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 1 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 2 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 3 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 4 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 5 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 6 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 7 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 8 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 9 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 10 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 11 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 12 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 13 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 14 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 15 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 16 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 17 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 18 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 19 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 20 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 21 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 22 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 23 88-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 0 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 1 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 2 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 3 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 4 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 5 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 6 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 7 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 8 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 9 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 10 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 11 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 12 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 13 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 14 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 15 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 16 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 17 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 18 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 19 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 20 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 21 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 22 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 23 89-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 0 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 1 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 2 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 3 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 4 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 5 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 6 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 7 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 8 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 9 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 10 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 11 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 12 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 13 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 14 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 15 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 16 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 17 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 18 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 19 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 20 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 21 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 22 90-th token inference finished ===================
[After loading specific expert weights] GPU memory allocated: 15.290 GB, reserved: 15.627 GB
================ Layer 23 90-th token inference finished ===================
Generation Time: 97.36 minutes
Model Output: systemYou are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-08-22

Reasoning: medium

# Valid channels: analysis, commentary, final. Channel must be included for every message.userRepeat after me: "My name is Morris."assistantanalysisThe user says: "Repeat after me: 'My name is Morris.'" They want the assistant to repeat that phrase. The assistant should respond with: "My name is Morris." That is the correct response. There's no trick. The user wants the assistant to repeat that phrase. So the assistant should respond with: "My name is Morris." That is the correct answer.assistantfinalMy name is Morris.
